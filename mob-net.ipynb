{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":129601,"databundleVersionId":15542776,"sourceType":"competition"}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Brain Tumor Segmentation — Hackathon Fast Pipeline\n\nModel: U-Net with EfficientNetB0 pretrained encoder\nModalities: FLAIR + T1ce\nStrategy:\n- 2.5D slice segmentation\n- tumor-slice filtering\n- memory-safe generator\n- Dice loss\n- RLE submission\n","metadata":{}},{"cell_type":"code","source":"import os\nimport glob\nimport random\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.utils import Sequence","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T06:34:25.377537Z","iopub.execute_input":"2026-02-04T06:34:25.377833Z","iopub.status.idle":"2026-02-04T06:34:42.008622Z","shell.execute_reply.started":"2026-02-04T06:34:25.377799Z","shell.execute_reply":"2026-02-04T06:34:42.008045Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import nibabel as nib\n\ndef load_nii(file_path):\n    return nib.load(file_path).get_fdata()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-03T19:29:27.773151Z","iopub.execute_input":"2026-02-03T19:29:27.773456Z","iopub.status.idle":"2026-02-03T19:29:27.90348Z","shell.execute_reply.started":"2026-02-03T19:29:27.773431Z","shell.execute_reply":"2026-02-03T19:29:27.902951Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def process_patient(patient_path):\n    import glob\n    # Flair & T1ce loading\n    flair_files = glob.glob(os.path.join(patient_path,\"*_flair.nii\",\"*.nii\")) or glob.glob(os.path.join(patient_path,\"*_flair.nii\"))\n    t1ce_files = glob.glob(os.path.join(patient_path,\"*_t1ce.nii\",\"*.nii\")) or glob.glob(os.path.join(patient_path,\"*_t1ce.nii\"))\n    \n    if not flair_files or not t1ce_files: return None, None\n    \n    f = load_nii(flair_files[0])\n    t = load_nii(t1ce_files[0])\n\n    def min_max_normalize(img):\n        img = np.nan_to_num(img)\n        low, high = np.percentile(img, [1, 99])\n        img = np.clip(img, low, high)\n        if (high - low) > 0:\n            return (img - low) / (high - low)\n        return img\n\n    slice_idx = f.shape[2] // 2\n    f_slice = min_max_normalize(f[:,:,slice_idx])\n    t_slice = min_max_normalize(t[:,:,slice_idx])\n\n    img_slice = np.stack([f_slice, t_slice], axis=-1).astype(np.float32)\n    img_slice = tf.image.resize(img_slice, (256,256))\n\n    # Mask processing\n    mask_files = glob.glob(os.path.join(patient_path,\"*_seg.nii\",\"*.nii\")) or glob.glob(os.path.join(patient_path,\"*_seg.nii\"))\n    if not mask_files: return img_slice, None\n    \n    m = load_nii(mask_files[0])\n    m_new = np.zeros_like(m)\n    m_new[m==1] = 1 # NCR\n    m_new[m==2] = 2 # ED\n    m_new[m==4] = 3 # ET\n    \n    mask_slice = tf.image.resize(m_new[:,:,slice_idx][..., np.newaxis], (256,256), method=\"nearest\")\n    mask_cat = tf.keras.utils.to_categorical(mask_slice, num_classes=4)\n    return img_slice, tf.cast(mask_cat, tf.float32)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-03T21:45:03.085763Z","iopub.execute_input":"2026-02-03T21:45:03.086576Z","iopub.status.idle":"2026-02-03T21:45:03.095105Z","shell.execute_reply.started":"2026-02-03T21:45:03.086546Z","shell.execute_reply":"2026-02-03T21:45:03.094131Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class BrainGenerator(Sequence):\n    def __init__(self, paths, batch_size=4, shuffle=True):\n        self.paths = paths\n        self.batch_size = batch_size\n        self.shuffle = shuffle\n        self.on_epoch_end()\n\n    def __len__(self):\n        return int(np.ceil(len(self.paths) / self.batch_size))\n\n    def __getitem__(self, idx):\n        batch_paths = self.paths[idx*self.batch_size : (idx+1)*self.batch_size]\n        imgs, masks = [], []\n        for p in batch_paths:\n            img, mask = process_patient(p)\n            if img is None or mask is None:\n                continue\n            imgs.append(img)\n            masks.append(mask)\n        if len(imgs)==0:\n            return self.__getitem__((idx+1) % self.__len__())\n        return np.array(imgs), np.array(masks)\n\n    def on_epoch_end(self):\n        if self.shuffle:\n            np.random.shuffle(self.paths)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-03T21:45:07.036458Z","iopub.execute_input":"2026-02-03T21:45:07.037238Z","iopub.status.idle":"2026-02-03T21:45:07.043474Z","shell.execute_reply.started":"2026-02-03T21:45:07.037206Z","shell.execute_reply":"2026-02-03T21:45:07.042693Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"TRAIN_DIR = \"/kaggle/input/instant-odc-ai-hackathon/Train\"\nall_patients = glob.glob(os.path.join(TRAIN_DIR,\"*\"))\nrandom.shuffle(all_patients)\nsplit = int(len(all_patients)*0.85)\ntrain_paths = all_patients[:split]\nval_paths = all_patients[split:]\n\ntrain_gen = BrainGenerator(train_paths, batch_size=4)\nval_gen = BrainGenerator(val_paths, batch_size=4)\n\nprint(\"Train patients:\", len(train_paths), \"Validation patients:\", len(val_paths))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-03T21:45:11.610632Z","iopub.execute_input":"2026-02-03T21:45:11.611382Z","iopub.status.idle":"2026-02-03T21:45:11.636163Z","shell.execute_reply.started":"2026-02-03T21:45:11.611355Z","shell.execute_reply":"2026-02-03T21:45:11.635518Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras import layers, models\nfrom tensorflow.keras.applications import MobileNetV2\n\n# Input: 256x256x2\ninp = layers.Input(shape=(256,256,2))\n\n# Convert 2 channels → 3 channels for pretrained MobileNetV2\nx = layers.Concatenate()([inp, inp[:,:,:,0:1]])  # shape = (256,256,3)\n\n# Pretrained MobileNetV2 encoder\nencoder = MobileNetV2(include_top=False, weights=\"imagenet\", input_tensor=x)\n\n# Extract feature maps from encoder\nx = encoder.output  # shape ~ (8,8,1280) or (16,16,1280) depending on MobileNetV2\n\n# Decoder: Upsampling blocks\nx = layers.Conv2D(512, 3, padding=\"same\", activation=\"relu\")(x)\nx = layers.UpSampling2D(2)(x)  # double size\nx = layers.Conv2D(256, 3, padding=\"same\", activation=\"relu\")(x)\nx = layers.UpSampling2D(2)(x)\nx = layers.Conv2D(128, 3, padding=\"same\", activation=\"relu\")(x)\nx = layers.UpSampling2D(2)(x)\nx = layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\")(x)\nx = layers.UpSampling2D(2)(x)\nx = layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\")(x)\nx = layers.UpSampling2D(2)(x)\n\n# Final output: 256x256x4\nout = layers.Conv2D(4, 1, activation=\"softmax\")(x)\n\nmodel = models.Model(inputs=inp, outputs=out)\nmodel.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\nmodel.summary()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-03T22:01:06.823265Z","iopub.execute_input":"2026-02-03T22:01:06.823575Z","iopub.status.idle":"2026-02-03T22:01:07.716816Z","shell.execute_reply.started":"2026-02-03T22:01:06.823552Z","shell.execute_reply":"2026-02-03T22:01:07.71623Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow.keras.backend as K\ndef dice_coef(y_true, y_pred, smooth=1e-6):\n    y_true_f = K.flatten(y_true[..., 1:]) \n    y_pred_f = K.flatten(y_pred[..., 1:])\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n\ndef dice_loss(y_true, y_pred):\n    return 1 - dice_coef(y_true, y_pred)\n\ndef combined_loss(y_true, y_pred):\n    ce = tf.keras.losses.categorical_crossentropy(y_true, y_pred)\n    dl = dice_loss(y_true, y_pred)\n    return ce + dl \n\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), \n    loss=combined_loss, \n    metrics=[dice_coef, 'accuracy']\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-03T22:01:20.652452Z","iopub.execute_input":"2026-02-03T22:01:20.652794Z","iopub.status.idle":"2026-02-03T22:01:20.663838Z","shell.execute_reply.started":"2026-02-03T22:01:20.652768Z","shell.execute_reply":"2026-02-03T22:01:20.662973Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"history = model.fit(\n    train_gen,\n    validation_data=val_gen,\n    epochs=15 \n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-03T22:01:37.338682Z","iopub.execute_input":"2026-02-03T22:01:37.339034Z","iopub.status.idle":"2026-02-03T23:58:21.721054Z","shell.execute_reply.started":"2026-02-03T22:01:37.339009Z","shell.execute_reply":"2026-02-03T23:58:21.719284Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nmodel.save(\"brats_segmentation_model.h5\")\nprint(\"Model saved successfully as brats_segmentation_model.h5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-03T20:57:54.908514Z","iopub.execute_input":"2026-02-03T20:57:54.908883Z","iopub.status.idle":"2026-02-03T20:57:55.696261Z","shell.execute_reply.started":"2026-02-03T20:57:54.908856Z","shell.execute_reply":"2026-02-03T20:57:55.695571Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import load_model\n\n# المسار اللي نسختيه\nmodel_path = '/kaggle/working/brats_segmentation_model.h5'\n\n# تحميل الموديل\ntry:\n    model = load_model(model_path)\n    print(\"Model Saved Succesfully\")\nexcept Exception as e:\n    print(f\" There is a problem {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T06:38:28.595429Z","iopub.execute_input":"2026-02-04T06:38:28.596156Z","iopub.status.idle":"2026-02-04T06:38:28.604217Z","shell.execute_reply.started":"2026-02-04T06:38:28.596123Z","shell.execute_reply":"2026-02-04T06:38:28.603444Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport cv2\nimport nibabel as nib\nimport glob\nimport tensorflow as tf\n\ndef rle_encode_final(mask_3d):\n    pixels = mask_3d.T.flatten() \n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    rle_string = ' '.join(str(x) for x in runs)\n    return rle_string if rle_string != \"\" else \"1 1\"\n\ndef min_max_normalize(img):\n    img = np.nan_to_num(img)\n    low, high = np.percentile(img, [1, 99])\n    img = np.clip(img, low, high)\n    if (high - low) > 0:\n        return (img - low) / (high - low)\n    return img\n\ndef predict_patient_ultimate_v2(patient_path):\n    path_flair = glob.glob(os.path.join(patient_path, '*_flair.nii'))[0]\n    path_t1ce  = glob.glob(os.path.join(patient_path, '*_t1ce.nii'))[0]\n    \n    v_flair = nib.load(path_flair).get_fdata()\n    v_t1ce  = nib.load(path_t1ce).get_fdata()\n    \n    v_flair_norm = min_max_normalize(v_flair)\n    v_t1ce_norm  = min_max_normalize(v_t1ce)\n    \n    final_volume = np.zeros((240, 240, 155, 4), dtype=np.float32)\n    \n    for slice_idx in range(155):\n        \n        f_slice = v_flair_norm[..., slice_idx]\n        t_slice = v_t1ce_norm[..., slice_idx]\n        \n        img_input = np.stack([f_slice, t_slice], axis=-1).astype(np.float32)\n    \n        img_input = tf.image.resize(img_input, (256, 256)).numpy() \n        \n        pred = model.predict(np.expand_dims(img_input, axis=0), verbose=0)[0]\n        \n        pred_res = cv2.resize(pred, (240, 240), interpolation=cv2.INTER_NEAREST)\n        final_volume[:, :, slice_idx, :] = pred_res\n        \n    return final_volume\n\nsubmission_list = []\nfor i, patient_path in enumerate(test_folders):\n    p_id = os.path.basename(patient_path)\n    if \"BraTS2021\" not in p_id: continue\n    \n    print(f\"⌛ Processing with Original Normalization: {p_id}\")\n    full_pred = predict_patient_ultimate_v2(patient_path)\n    \n    for suffix, ch_idx in {\"1\": 1, \"2\": 2, \"4\": 3}.items():\n        mask_binary = (full_pred[..., ch_idx] > 0.5).astype(np.uint8)\n        submission_list.append({\"id\": f\"{p_id}_{suffix}\", \"rle\": rle_encode_final(mask_binary)})\n\ndf_final = pd.DataFrame(submission_list)\nsample = pd.read_csv(\"/kaggle/input/instant-odc-ai-hackathon/sample_submission.csv\")\nfinal_sub = pd.merge(sample[['id']], df_final, on='id', how='left').fillna(\"1 1\")\nfinal_sub = final_sub.drop_duplicates(subset=['id'], keep='first')\nfinal_sub.to_csv(\"SUBMISSION_WITH_NORM.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T05:02:00.171527Z","iopub.execute_input":"2026-02-04T05:02:00.172402Z","execution_failed":"2026-02-04T05:15:50.049Z"}},"outputs":[],"execution_count":null}]}